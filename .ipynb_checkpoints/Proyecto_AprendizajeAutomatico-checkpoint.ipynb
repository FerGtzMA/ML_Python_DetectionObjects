{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0e0a2b",
   "metadata": {},
   "source": [
    "# FERNANDO YAHIR GUTIERREZ SANTOYO 1917844"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9344262d",
   "metadata": {},
   "source": [
    "# Detección de Objetos de señales víales\n",
    "\n",
    "Conseguimos la dataset con las fotos de 48x48 del archivo traffic_signs_x_train_gr_smpl.csv hecho por el profesor de la materia. También tenemos las categorías en el archivo traffic_signs_y_train_smpl.csv que al igual que el primero, lo proporcionó el profesor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6886fe",
   "metadata": {},
   "source": [
    "#### Vamos a Crear una Red Neuronal para:\n",
    "1. Crear una red neuronalartificialla cual tenga la capacidad de identificar las siguientes señales de tráfico:\n",
    "0. speed limit 60, \n",
    "1. speed limit 80, \n",
    "2. speed limit 80 lifted, \n",
    "3. right of way at crossing, \n",
    "4. right of way in general, \n",
    "5. give way, \n",
    "6. Stop, \n",
    "7. no speed limit general, \n",
    "8. turn right down, \n",
    "9. turn left down. \n",
    "Existen 10 categorías de señales, las cuales están identificadas con números del 0 al 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139323d",
   "metadata": {},
   "source": [
    "Tenemos que descargar primero las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16746db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow==1.13.2\n",
    "#pip install keras==2.0.8\n",
    "#pip install imgaug==0.2.5\n",
    "#pip install opencv-python\n",
    "#pip install h5py\n",
    "#pip install tqdm\n",
    "#pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a211dc",
   "metadata": {},
   "source": [
    "Después las importamos en nuestra neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84bc9b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import copy\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.utils import Sequence\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b30dd6d",
   "metadata": {},
   "source": [
    "### Definimos el directorio de anotaciones xml/csv e imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = \"annotation/traffic_signs_x_train_gr_smpl.csv/\"  # directorio que contiene los csv\n",
    "img_dir = \"images/traffic_signs_x_train_gr_smpl.csv/\"   # directorios con las imagenes\n",
    "labels = [\"speed limit 60\", \"speed limit 80\", \"speed limit 80 lifted\", \" right of way at crossing\", \n",
    "          \"right of way in general\", \"give way\", \"Stop\", \"no speed limit\", \"turn right down\", \"turn left down\"]\n",
    "tamanio = 48*48  # tamanio en pixeles para entrenar la red\n",
    "mejores_pesos = \"red_seniales_trafico.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_annotations(ann_dir, img_dir, labels=[]):\n",
    "    all_imgs = []\n",
    "    seen_labels = {}\n",
    "    \n",
    "    for ann in [x for x in sorted(os.listdir(ann_dir)) if x.endswith('.csv')] :\n",
    "        img = {'object':[]}\n",
    "        \n",
    "        tree = ET.parse(ann_dir + ann)\n",
    "        \n",
    "        for elem in tree.iter():\n",
    "            if 'filename' in elem.tag:\n",
    "                img['filename'] = img_dir + elem.text\n",
    "            if 'width' in elem.tag:\n",
    "                img['width'] = int(elem.text)\n",
    "            if 'height' in elem.tag:\n",
    "                img['height'] = int(elem.text)\n",
    "            if 'object' in elem.tag or 'part' in elem.tag:\n",
    "                obj = {}\n",
    "                \n",
    "                for attr in list(elem):\n",
    "                    if 'name' in attr.tag:\n",
    "                        obj['name'] = attr.text\n",
    "\n",
    "                        if obj['name'] in seen_labels:\n",
    "                            seen_labels[obj['name']] += 1\n",
    "                        else:\n",
    "                            seen_labels[obj['name']] = 1\n",
    "                        \n",
    "                        if len(labels) > 0 and obj['name'] not in labels:\n",
    "                            break\n",
    "                        else:\n",
    "                            img['object'] += [obj]\n",
    "                            \n",
    "                    if 'bndbox' in attr.tag:\n",
    "                        for dim in list(attr):\n",
    "                            if 'xmin' in dim.tag:\n",
    "                                obj['xmin'] = int(round(float(dim.text)))\n",
    "                            if 'ymin' in dim.tag:\n",
    "                                obj['ymin'] = int(round(float(dim.text)))\n",
    "                            if 'xmax' in dim.tag:\n",
    "                                obj['xmax'] = int(round(float(dim.text)))\n",
    "                            if 'ymax' in dim.tag:\n",
    "                                obj['ymax'] = int(round(float(dim.text)))\n",
    "\n",
    "        if len(img['object']) > 0:\n",
    "            all_imgs += [img]\n",
    "                        \n",
    "    return all_imgs, seen_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c0a15",
   "metadata": {},
   "source": [
    "Y ahora las cargamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cdd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_labels = leer_annotations(csv_dir, img_dir, labels)\n",
    "print('imagenes',len(train_imgs), 'labels',len(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d6abc",
   "metadata": {},
   "source": [
    "### Separamos en Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c47d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_split = int(0.8*len(train_imgs))\n",
    "np.random.shuffle(train_imgs)\n",
    "valid_imgs = train_imgs[train_valid_split:]\n",
    "train_imgs = train_imgs[:train_valid_split]\n",
    "print('train:',len(train_imgs), 'validate:',len(valid_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08530420",
   "metadata": {},
   "source": [
    "### Argumentamos los datos\n",
    "\n",
    "Esto lo hacemos haciendo pequeñas distorciones a las imagenes de entrada para entrenar con mayor variedad y mejorar la precision de la red.\n",
    "Para hacerlo nos apoyamos sobre una librería llamada imgaug que nos brinda muchas funcionalidades como agregar desenfoque, agregar brillo, ó ruido aleatoriamente a las imágenes. Además podemos usar OpenCV para voltear la imagen horizontalmente y luego recolocar la “bounding box”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6925845",
   "metadata": {},
   "outputs": [],
   "source": [
    "iaa.OneOf([\n",
    "    iaa.GaussianBlur((0, 3.0)), # blur images\n",
    "    iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel\n",
    "    iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel\n",
    "    ]),\n",
    "    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "    iaa.OneOf([;\n",
    "        iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "        ]),\n",
    "    iaa.Add((-10, 10), per_channel=0.5), # change brightness of images\n",
    "    iaa.Multiply((0.5, 1.5), per_channel=0.5), # change brightness of images\n",
    "    iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3348c02",
   "metadata": {},
   "source": [
    "### Crear la rede de clasificación\n",
    "\n",
    "La red CNN es conocida como Darknet y está compuesta por 22 capas convolucionales que básicamente aplican BatchNormalizarion, MaxPooling y activación por LeakyRelu para la extracción de características, es decir, los patrones que encontrará en las imágenes (en sus pixeles) para poder diferenciar entre los objetos que queremos clasificar.\n",
    "\n",
    "Va alternando entre aumentar y disminuir la cantidad de filtros y kernel de 3×3 y 1×1 de la red convolucional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a201923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8723ff8",
   "metadata": {},
   "source": [
    "### Ahora creamos la red de detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image     = Input(shape=(self.input_size, self.input_size, 3))\n",
    "self.true_boxes = Input(shape=(1, 1, 1, max_box_per_image , 4))  \n",
    " \n",
    "self.feature_extractor = FullYoloFeature(self.input_size)\n",
    " \n",
    "print(self.feature_extractor.get_output_shape())    \n",
    "self.grid_h, self.grid_w = self.feature_extractor.get_output_shape()        \n",
    "features = self.feature_extractor.extract(input_image)            \n",
    " \n",
    "# make the object detection layer\n",
    "output = Conv2D(self.nb_box * (4 + 1 + self.nb_class), \n",
    "         (1,1), strides=(1,1), \n",
    "         padding='same', \n",
    "         name='DetectionLayer', \n",
    "         kernel_initializer='lecun_normal')(features)\n",
    "output = Reshape((self.grid_h, self.grid_w, self.nb_box, 4 + 1 + self.nb_class))(output)\n",
    "output = Lambda(lambda args: args[0])([output, self.true_boxes])\n",
    " \n",
    "self.model = Model([input_image, self.true_boxes], output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2b05b",
   "metadata": {},
   "source": [
    "En total, la red YOLO crea una grilla de 13×13 y en cada una realizará 10 predicciones, lo que da un total de 8450 posibles detecciones para cada clase, cada una con la clase y sus posiciones x,y ancho y alto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a365d5",
   "metadata": {},
   "source": [
    "## ENTRENAMOS LA RED NEURONAL con YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73755420",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO(input_size          = tamanio, \n",
    "            labels              = labels, \n",
    "            max_box_per_image   = 10,\n",
    "            anchors             = anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acadc6",
   "metadata": {},
   "source": [
    "## Probar la RED\n",
    "\n",
    "Para finalizar, podemos probar la red con imágenes nuevas, distintas que no ha visto nunca, veamos cómo se comporta la red!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e987279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, boxes, labels):\n",
    "    image_h, image_w, _ = image.shape\n",
    " \n",
    "    for box in boxes:\n",
    "        xmin = int(box.xmin*image_w)\n",
    "        ymin = int(box.ymin*image_h)\n",
    "        xmax = int(box.xmax*image_w)\n",
    "        ymax = int(box.ymax*image_h)\n",
    " \n",
    "        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
    "        cv2.putText(image, \n",
    "                    labels[box.get_label()] + ' ' + str(box.get_score()), \n",
    "                    (xmin, ymin - 13), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1e-3 * image_h, \n",
    "                    (0,255,0), 2)\n",
    "        \n",
    "    return image  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
